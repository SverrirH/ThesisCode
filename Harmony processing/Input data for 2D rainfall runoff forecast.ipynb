{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "from pyproj import Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "import wradlib as wrl\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import pygrib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_Harmony = 'F:/harmonie'\n",
    "DIR_Harmony_save = 'F:/harmony processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:/harmonie\\\\201510',\n",
       " 'F:/harmonie\\\\201511',\n",
       " 'F:/harmonie\\\\201512',\n",
       " 'F:/harmonie\\\\201601',\n",
       " 'F:/harmonie\\\\201602',\n",
       " 'F:/harmonie\\\\201603',\n",
       " 'F:/harmonie\\\\201604',\n",
       " 'F:/harmonie\\\\201605',\n",
       " 'F:/harmonie\\\\201606',\n",
       " 'F:/harmonie\\\\201607',\n",
       " 'F:/harmonie\\\\201608',\n",
       " 'F:/harmonie\\\\201609',\n",
       " 'F:/harmonie\\\\201610',\n",
       " 'F:/harmonie\\\\201611',\n",
       " 'F:/harmonie\\\\201612',\n",
       " 'F:/harmonie\\\\201701',\n",
       " 'F:/harmonie\\\\201702',\n",
       " 'F:/harmonie\\\\201703',\n",
       " 'F:/harmonie\\\\201704',\n",
       " 'F:/harmonie\\\\201705',\n",
       " 'F:/harmonie\\\\201706',\n",
       " 'F:/harmonie\\\\201707',\n",
       " 'F:/harmonie\\\\201708',\n",
       " 'F:/harmonie\\\\201709',\n",
       " 'F:/harmonie\\\\201710',\n",
       " 'F:/harmonie\\\\201711',\n",
       " 'F:/harmonie\\\\201712',\n",
       " 'F:/harmonie\\\\201801',\n",
       " 'F:/harmonie\\\\201802',\n",
       " 'F:/harmonie\\\\201803',\n",
       " 'F:/harmonie\\\\201804',\n",
       " 'F:/harmonie\\\\201805',\n",
       " 'F:/harmonie\\\\201806',\n",
       " 'F:/harmonie\\\\201807',\n",
       " 'F:/harmonie\\\\201808',\n",
       " 'F:/harmonie\\\\201809',\n",
       " 'F:/harmonie\\\\201810',\n",
       " 'F:/harmonie\\\\201811',\n",
       " 'F:/harmonie\\\\201812',\n",
       " 'F:/harmonie\\\\201901',\n",
       " 'F:/harmonie\\\\201902',\n",
       " 'F:/harmonie\\\\201903',\n",
       " 'F:/harmonie\\\\201904',\n",
       " 'F:/harmonie\\\\201905',\n",
       " 'F:/harmonie\\\\201906',\n",
       " 'F:/harmonie\\\\201907',\n",
       " 'F:/harmonie\\\\201908',\n",
       " 'F:/harmonie\\\\201909',\n",
       " 'F:/harmonie\\\\201910',\n",
       " 'F:/harmonie\\\\201911',\n",
       " 'F:/harmonie\\\\201912',\n",
       " 'F:/harmonie\\\\202001',\n",
       " 'F:/harmonie\\\\202002',\n",
       " 'F:/harmonie\\\\202003',\n",
       " 'F:/harmonie\\\\202004',\n",
       " 'F:/harmonie\\\\202005',\n",
       " 'F:/harmonie\\\\202006',\n",
       " 'F:/harmonie\\\\202007',\n",
       " 'F:/harmonie\\\\202008',\n",
       " 'F:/harmonie\\\\202009',\n",
       " 'F:/harmonie\\\\202010',\n",
       " 'F:/harmonie\\\\202011',\n",
       " 'F:/harmonie\\\\202012']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('F:/harmonie/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = np.array(glob(DIR_Harmony + '/*/*'))\n",
    "\n",
    "df_meta = pd.DataFrame(urls,columns=['url'])\n",
    "\n",
    "timestring_start = len('2015100100.00')\n",
    "timestring_end = len('.00')\n",
    "extract_timestring = lambda x : x[-timestring_start:-timestring_end]\n",
    "extract_timestamp = lambda x : datetime.datetime(int(x[:4]),int(x[4:6]),int(x[6:8]),int(x[8:10]))\n",
    "timestamps = np.array([extract_timestamp(extract_timestring(u)) for u in urls])\n",
    "df_meta.loc[:,'datetime'] = timestamps\n",
    "df_meta.loc[:,'pred dist'] = df_meta.loc[:,'url'].str[-2:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_a = np.array([extract_timestring(u) for u in urls])\n",
    "# tmp_b = np.array([extract_timestamp(u) for u in tmp_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parameter_info(parameter_list, param_number):\n",
    "    ''' Takes a number for the parameter of interest, \n",
    "        returns various information incl. gridded values '''\n",
    "    parameter_list[param_number].dataDate\n",
    "    parameter_list[param_number].parameterName\n",
    "    parameter_list[param_number].indicatorOfTypeOfLevel\n",
    "    parameter_list[param_number].typeOfLevel\n",
    "    parameter_list[param_number].latitudes\n",
    "    parameter_list[param_number].longitudes\n",
    "    parameter_list[param_number].values\n",
    "    \n",
    "    parameter_list[param_number].Ni\n",
    "    parameter_list[param_number].Nj\n",
    "    \n",
    "    \n",
    "    lats = parameter_list[param_number].latitudes.reshape(parameter_list[param_number].Nj, parameter_list[param_number].Ni)\n",
    "    lons = parameter_list[param_number].longitudes.reshape(parameter_list[param_number].Nj, parameter_list[param_number].Ni)\n",
    "    grid_values = parameter_list[param_number].values.reshape(parameter_list[param_number].Nj, parameter_list[param_number].Ni)\n",
    "    \n",
    "    \n",
    "    param_output = {\"date\": parameter_list[param_number].dataDate,\n",
    "                    \"grib_number\": parameter_list[param_number].parameterName,\n",
    "                    \"indicator_type\": parameter_list[param_number].indicatorOfTypeOfLevel,\n",
    "                    \"type_of_level\": parameter_list[param_number].indicatorOfTypeOfLevel,\n",
    "                    \"lats\": lats,\n",
    "                    \"lons\": lons,\n",
    "                    \"values\": grid_values}\n",
    "    return(param_output)\n",
    "def nwp_plot(rain_array, lons, lats, bg_map_file, plot_title):\n",
    "    ''' Function that plots gridded NWP data'''\n",
    "    bg_map = gpd.read_file(bg_map_file)\n",
    "    \n",
    "    # create custom color map\n",
    "    #cmap = colors.ListedColormap([\"#85E3E4\", '#42D8D8', '#42AFD8', '#4282D8', \"#FFE600\", '#FFAF00', '#FF5050', '#FF1A1A', \"#BD0000\", \"#8C0000\"])\n",
    "    #boundaries = [0, .5, 1, 2, 3, 4, 5, 7.5, 10, 15, 20]\n",
    "    #norm = colors.BoundaryNorm(boundaries, cmap.N, clip=True)\n",
    "    \n",
    "    bg_map.plot(facecolor=\"lightgrey\")\n",
    "    plt.pcolor(lons, lats, rain_array, shading = \"auto\", alpha=0.8)#, cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    #cbar.ax.set_ylabel('Rainfall intensity [mm/h]', rotation=90)\n",
    "    #plt.xlim(7,15) # longitudes for Denmark (for a zoomed plot)\n",
    "    #plt.ylim(54.5,58) # lattitudes for Denmark (for a zoomed plot)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.title(plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = df_meta.sort_values(['datetime','pred dist'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly indicators for filtering\n",
    "datetime_series = pd.DatetimeIndex(df_meta.datetime)\n",
    "months = ['%02d' % i for i in datetime_series.month]\n",
    "years = [str(i) for i in datetime_series.year]\n",
    "df_meta.loc[:,'year and month'] = [a+b for a,b in zip(years,months)]\n",
    "df_start_end = pd.concat([df_meta.groupby('year and month').min().loc[:,'datetime'],df_meta.groupby('year and month').max().loc[:,'datetime']],axis=1)\n",
    "df_start_end.columns = ['start','end']\n",
    "df_meta_group_lists = df_meta.groupby('datetime').apply(lambda x: list(x.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "tmp = df_meta.iloc[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/harmony processed/201511_data.npy\n",
      "F:/harmony processed/201512_data.npy\n",
      "F:/harmony processed/201601_data.npy\n",
      "F:/harmony processed/201602_data.npy\n",
      "F:/harmony processed/201603_data.npy\n",
      "F:/harmony processed/201604_data.npy\n",
      "F:/harmony processed/201605_data.npy\n",
      "F:/harmony processed/201606_data.npy\n",
      "F:/harmony processed/201607_data.npy\n",
      "F:/harmony processed/201608_data.npy\n",
      "F:/harmony processed/201609_data.npy\n",
      "F:/harmony processed/201610_data.npy\n",
      "F:/harmony processed/201611_data.npy\n",
      "F:/harmony processed/201612_data.npy\n",
      "F:/harmony processed/201701_data.npy\n",
      "F:/harmony processed/201702_data.npy\n",
      "F:/harmony processed/201703_data.npy\n",
      "F:/harmony processed/201704_data.npy\n",
      "F:/harmony processed/201705_data.npy\n",
      "F:/harmony processed/201706_data.npy\n",
      "F:/harmony processed/201707_data.npy\n",
      "F:/harmony processed/201708_data.npy\n",
      "F:/harmony processed/201709_data.npy\n",
      "F:/harmony processed/201710_data.npy\n",
      "F:/harmony processed/201711_data.npy\n",
      "F:/harmony processed/201712_data.npy\n",
      "F:/harmony processed/201801_data.npy\n",
      "F:/harmony processed/201802_data.npy\n",
      "F:/harmony processed/201803_data.npy\n",
      "F:/harmony processed/201804_data.npy\n",
      "F:/harmony processed/201805_data.npy\n",
      "F:/harmony processed/201806_data.npy\n",
      "F:/harmony processed/201807_data.npy\n",
      "F:/harmony processed/201808_data.npy\n",
      "F:/harmony processed/201809_data.npy\n",
      "F:/harmony processed/201810_data.npy\n",
      "F:/harmony processed/201811_data.npy\n",
      "F:/harmony processed/201901_data.npy\n",
      "F:/harmony processed/201902_data.npy\n",
      "F:/harmony processed/201903_data.npy\n",
      "F:/harmony processed/201904_data.npy\n",
      "F:/harmony processed/201905_data.npy\n",
      "F:/harmony processed/201906_data.npy\n",
      "F:/harmony processed/201909_data.npy\n",
      "F:/harmony processed/201910_data.npy\n",
      "F:/harmony processed/201911_data.npy\n",
      "F:/harmony processed/201912_data.npy\n",
      "F:/harmony processed/202001_data.npy\n",
      "F:/harmony processed/202002_data.npy\n",
      "F:/harmony processed/202003_data.npy\n",
      "F:/harmony processed/202004_data.npy\n",
      "F:/harmony processed/202005_data.npy\n",
      "F:/harmony processed/202006_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 202006: 100%|██████████| 118/118 [01:04<00:00,  1.83it/s]\n",
      "C:\\Users\\sverrirhd\\Anaconda3\\envs\\gis_wradlib_torch\\lib\\site-packages\\numpy\\lib\\npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/harmony processed/202007_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 202007: 100%|██████████| 124/124 [01:51<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/harmony processed/202008_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 202008: 100%|██████████| 117/117 [02:18<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/harmony processed/202009_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 202009: 100%|██████████| 120/120 [02:57<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/harmony processed/202010_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 202010: 100%|██████████| 124/124 [02:31<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/harmony processed/202011_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 202011: 100%|██████████| 120/120 [02:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/harmony processed/202012_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 202012: 100%|██████████| 119/119 [02:18<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# initialization so the variables are defined outside the scope of the for loop\n",
    "\n",
    "raw_data_list = []\n",
    "# one month at a time for easier debugging\n",
    "for index,row in df_start_end.loc['201511':].iterrows():\n",
    "    # print(index)\n",
    "    URL_data = f'{DIR_Harmony_save}{index}_data.npy'\n",
    "    URL_urls = f'{DIR_Harmony_save}{index}_urls.npy'\n",
    "    URL_shapes = f'{DIR_Harmony_save}{index}_shapes.npy'\n",
    "    print(URL_data)\n",
    "    \n",
    "    if len(glob(URL_data)) > 0:\n",
    "        continue\n",
    "    \n",
    "    # timestamps for first and last images of month\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    \n",
    "    # Subset of month\n",
    "    monthly_subset = df_meta_group_lists.loc[start:end]\n",
    "    len_subset = len(monthly_subset)\n",
    "    # Iterate over radar slices\n",
    "    \n",
    "    pbar = tqdm(range(len_subset))\n",
    "    pbar.set_description(\"Processing %s\" % index)\n",
    "    monthly_data = []\n",
    "    urls = []\n",
    "    shapes = []\n",
    "    for indx,single_scan_indexes in zip(pbar,monthly_subset):\n",
    "        single_scan = df_meta.loc[single_scan_indexes]\n",
    "        tmp_urls = single_scan.loc[:,'url'].values\n",
    "        \n",
    "        # Can crash if a file is corrupted\n",
    "        try:\n",
    "            data = np.array([pygrib.open(i).read()[0].values for i in tmp_urls])\n",
    "        except KeyboardInterrupt: # for early stopping\n",
    "            assert False\n",
    "        except: # For other kinds of errors\n",
    "            problematic_indexes.append(single_scan_indexes)\n",
    "            continue # just skip the whole thing\n",
    "        \n",
    "        shapes.append(data.shape)\n",
    "        \n",
    "        if data.shape != (67, 469, 489):\n",
    "            data_tmp = np.zeros((67, 469, 489))\n",
    "            f,xr,yr = data.shape\n",
    "            data_tmp[:f,:xr,:yr] = data\n",
    "            data = data_tmp\n",
    "            \n",
    "        \n",
    "        monthly_data.append(data)\n",
    "        urls.append(tmp_urls)\n",
    "    monthly_data_tensor = np.array(monthly_data,dtype='float32')\n",
    "    \n",
    "    np.save(URL_data,monthly_data_tensor)\n",
    "    np.save(URL_urls,urls)\n",
    "    np.save(URL_shapes,np.array(shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37b26b0919f3eebb53e1fb9d1c196dfd7351d15ccc4a50e8438da0372db545ef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('gis_wradlib_torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

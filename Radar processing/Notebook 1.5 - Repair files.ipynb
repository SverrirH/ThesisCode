{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract exactly which files were unable to load during extraction of CAPPI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "from pyproj import Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "import wradlib as wrl\n",
    "import re\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drainage and raingauge url\n",
    "URL_gauge_data = 'C:/Users/sverrirhd/Google Drive/SkÃ³li/DTU/Thesis/Data/Rain gauges/'\n",
    "URL_gauge_2020_file = URL_gauge_data + 'clean2020data1475.csv'\n",
    "URL_saved_sensor_data = URL_gauge_data + 'hbs_lysigogn.csv'\n",
    "DIR_data = 'C:/Users/sverrirhd/vedurgogn/'\n",
    "DIR_rain_gauges = glob(URL_gauge_data + '*cleaned*')\n",
    "\n",
    "# Radar urls\n",
    "# DIR_CAPPI = 'C:/Users/sverrirhd/OneDrive/CAPPI/'\n",
    "DIR_CAPPI = 'F:/CAPPI/'\n",
    "\n",
    "urls_cappi = np.array(glob(DIR_CAPPI + 'CAPPI_[0-9][0-9][0-9][0-9][0-9][0-9]*'))\n",
    "urls_cappi_mask = np.array(glob(DIR_CAPPI + 'CAPPI_MASK*'))\n",
    "urls_descr = np.array(glob(DIR_CAPPI + 'descriptive_data*'))\n",
    "urls_probl = np.array(glob(DIR_CAPPI + 'problematic_indexes*'))\n",
    "urls_urls = np.array(glob(DIR_CAPPI + 'urls*'))\n",
    "\n",
    "urls_cappi_2020 = urls_cappi[['2020' in i for i in urls_cappi]]\n",
    "urls_cappi_mask_2020 = urls_cappi_mask[['2020' in i for i in urls_cappi_mask]]\n",
    "urls_descr_2020 = urls_descr[['2020' in i for i in urls_descr]]\n",
    "urls_probl_2020 = urls_probl[['2020' in i for i in urls_probl] ]\n",
    "urls_urls_2020 = urls_urls[['2020' in i for i in urls_urls]]\n",
    "\n",
    "urls_cappi = urls_cappi[[url not in urls_cappi_2020 for url in urls_cappi]]\n",
    "urls_cappi_mask = urls_cappi_mask[[url not in urls_cappi_mask_2020 for url in urls_cappi_mask]]\n",
    "urls_descr = urls_descr[[url not in urls_descr_2020 for url in urls_descr]]\n",
    "urls_probl = urls_probl[[url not in urls_probl_2020 for url in urls_probl]]\n",
    "urls_urls = urls_urls[[url not in urls_urls_2020 for url in urls_urls]]\n",
    "\n",
    "df_file_urls = pd.DataFrame([urls_cappi,urls_cappi_mask,urls_descr,urls_probl,urls_urls]).T\n",
    "df_file_urls.columns = ['CAPPI','CAPPI_mask','descriptive_data','problematic_indexes','urls']\n",
    "df_file_urls.loc[:,'yearmonth'] = df_file_urls.CAPPI.str.findall('[0-9][0-9][0-9][0-9][0-9][0-9]').apply(lambda x : x[0])\n",
    "\n",
    "df_file_urls.loc[:,'filetype'] = df_file_urls.CAPPI.str.findall('hdf5').apply(lambda x: 'hdf5' if len(x) > 0 else 'h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_urls = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('201501', 'h5')\n",
      "('201502', 'h5')\n",
      "('201503', 'h5')\n",
      "('201504', 'h5')\n",
      "('201505', 'h5')\n",
      "('201506', 'h5')\n",
      "('201507', 'h5')\n",
      "('201508', 'h5')\n",
      "('201509', 'h5')\n",
      "('201510', 'h5')\n",
      "('201511', 'h5')\n",
      "('201512', 'h5')\n",
      "('201601', 'h5')\n",
      "('201602', 'h5')\n",
      "('201603', 'h5')\n",
      "('201604', 'h5')\n",
      "('201605', 'h5')\n",
      "('201606', 'h5')\n",
      "('201607', 'h5')\n",
      "('201608', 'h5')\n",
      "('201609', 'h5')\n",
      "('201610', 'h5')\n",
      "('201611', 'h5')\n",
      "('201612', 'h5')\n",
      "('201701', 'h5')\n",
      "('201702', 'h5')\n",
      "('201703', 'h5')\n",
      "('201704', 'h5')\n",
      "('201705', 'h5')\n",
      "('201706', 'h5')\n",
      "('201707', 'h5')\n",
      "('201708', 'h5')\n",
      "('201709', 'h5')\n",
      "('201710', 'h5')\n",
      "('201711', 'h5')\n",
      "('201712', 'h5')\n",
      "('201801', 'h5')\n",
      "('201801', 'hdf5')\n",
      "('201802', 'h5')\n",
      "('201802', 'hdf5')\n",
      "('201803', 'h5')\n",
      "('201803', 'hdf5')\n",
      "('201804', 'hdf5')\n",
      "('201805', 'hdf5')\n",
      "('201806', 'hdf5')\n",
      "('201807', 'hdf5')\n",
      "('201808', 'hdf5')\n",
      "('201809', 'hdf5')\n",
      "('201810', 'hdf5')\n",
      "('201811', 'hdf5')\n",
      "('201812', 'hdf5')\n",
      "('201901', 'hdf5')\n",
      "('201902', 'hdf5')\n",
      "('201903', 'hdf5')\n",
      "('201904', 'hdf5')\n",
      "('201905', 'hdf5')\n",
      "('201906', 'hdf5')\n",
      "('201907', 'hdf5')\n",
      "('201908', 'hdf5')\n",
      "('201909', 'hdf5')\n",
      "('201910', 'hdf5')\n",
      "('201911', 'hdf5')\n",
      "('201912', 'hdf5')\n"
     ]
    }
   ],
   "source": [
    "# Takes about 90s (on hard drive, but more like 20 minutes from external hard drive) \n",
    "for index,row in df_file_urls.iterrows():\n",
    "    problematic_indexes_urls = row['problematic_indexes']\n",
    "    \n",
    "    year_month = row['yearmonth']\n",
    "    filetype = row['filetype']\n",
    "    key = (year_month,filetype)\n",
    "    print(key)\n",
    "    prob_indx = np.load(problematic_indexes_urls, allow_pickle=True)\n",
    "    \n",
    "    problematic_urls[key] =  prob_indx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate the index dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_vedur = 'F:/'\n",
    "df_meta = pd.read_csv('./Analysis/file_metadata.csv',index_col=0)\n",
    "df_meta.url = df_meta.url.str.replace('C:/Users/sverrirhd/vedurgogn//',DIR_vedur)\n",
    "df_meta.ctime = pd.to_datetime(df_meta.ctime)\n",
    "df_meta.loc[:,'year and month'] = df_meta.ctime.apply(lambda x : str(x.year) + '%02d' % x.month)\n",
    "months = df_meta.loc[:,'year and month'].sort_index().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_h5 = df_meta.loc[df_meta.loc[:,'extension'] == '.H5']\n",
    "df_meta_h5_group_lists = df_meta_h5.groupby('ctime').apply(lambda x: list(x.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2015-01-24 18:45:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2015-03-06 09:30:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2015-04-04 18:00:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2015-05-02 22:30:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2015-06-04 19:45:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2015-07-10 15:30:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2015-08-24 08:30:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2015-08-25 22:15:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-01-05 05:30:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-03-04 19:00:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-06-25 11:15:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-07-02 19:00:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-07-08 22:15:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-07-12 05:30:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-08-24 04:00:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-10-11 22:00:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-11-26 14:30:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2016-12-16 02:30:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-01-23 13:00:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-02-04 05:45:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-07-08 04:10:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-07-27 07:25:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-08-11 00:40:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-08-14 00:55:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-09-14 03:40:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-09-30 19:40:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2017-12-18 09:40:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2018-02-20 13:55:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n",
      "DatetimeIndex(['2018-03-05 07:55:00'], dtype='datetime64[ns]', name='ctime', freq=None)\n"
     ]
    }
   ],
   "source": [
    "bad_timestamps = []\n",
    "for key in problematic_urls:\n",
    "    bad_index_list = problematic_urls[key]\n",
    "    for bi in bad_index_list:\n",
    "        matches = df_meta_h5_group_lists.apply(lambda x : x == bi).apply(sum) > 0\n",
    "        bad_ts = df_meta_h5_group_lists.loc[matches].index\n",
    "        # print(bad_ts)\n",
    "        bad_timestamps.append(bad_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_save = 'F:/CAPPI/'\n",
    "np.save(DIR_save + 'missing_dates_all', bad_timestamps, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# go through each date_file and remove the file if it's in missing dates and then resave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_datestring = lambda x : re.findall('20[1-2][5-9][0-1][0-9][0-3][0-9][0-2][0-9][0-5][0-9]',x.replace('_',''))\n",
    "extract_date = lambda x : datetime.datetime(int(x[:4]),int(x[4:6]),int(x[6:8]),int(x[8:10]),int(x[10:12]))\n",
    "for index,row in df_file_urls.iterrows():\n",
    "    # Load the data\n",
    "    urls = row['urls']\n",
    "    year_month = row['yearmonth']\n",
    "    filetype = row['filetype']\n",
    "    CAPPI_url = row['CAPPI']\n",
    "    problematic_indx = row['problematic_indexes']\n",
    "    \n",
    "    key = (year_month,filetype)\n",
    "\n",
    "    # Match the date to the index from the original_urls file\n",
    "    raw_urls = np.load(urls,allow_pickle=True)\n",
    "    datestrings = [extract_datestring(url[0]) for url in raw_urls] \n",
    "    datetimes = [extract_date(datestr[0]) for datestr in datestrings]\n",
    "    removeable_index = np.argwhere([i in dt_missing_dates for i in datetimes]).ravel()\n",
    "    \n",
    "    urls_new = np.delete(raw_urls,removeable_index,0)\n",
    "    np.save(urls, urls_new,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_missing_dates = pd.to_datetime(np.array(bad_timestamps)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.delete(a,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([2, 3]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPPI</th>\n",
       "      <th>CAPPI_mask</th>\n",
       "      <th>descriptive_data</th>\n",
       "      <th>problematic_indexes</th>\n",
       "      <th>urls</th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>filetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201501.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201501.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201501.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201501.npy</td>\n",
       "      <td>F:/CAPPI\\urls201501.npy</td>\n",
       "      <td>201501</td>\n",
       "      <td>h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201502.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201502.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201502.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201502.npy</td>\n",
       "      <td>F:/CAPPI\\urls201502.npy</td>\n",
       "      <td>201502</td>\n",
       "      <td>h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201503.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201503.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201503.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201503.npy</td>\n",
       "      <td>F:/CAPPI\\urls201503.npy</td>\n",
       "      <td>201503</td>\n",
       "      <td>h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201504.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201504.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201504.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201504.npy</td>\n",
       "      <td>F:/CAPPI\\urls201504.npy</td>\n",
       "      <td>201504</td>\n",
       "      <td>h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201505.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201505.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201505.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201505.npy</td>\n",
       "      <td>F:/CAPPI\\urls201505.npy</td>\n",
       "      <td>201505</td>\n",
       "      <td>h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201908_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201908_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201908_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201908_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\urls201908_hdf5.npy</td>\n",
       "      <td>201908</td>\n",
       "      <td>hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201909_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201909_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201909_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201909_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\urls201909_hdf5.npy</td>\n",
       "      <td>201909</td>\n",
       "      <td>hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201910_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201910_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201910_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201910_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\urls201910_hdf5.npy</td>\n",
       "      <td>201910</td>\n",
       "      <td>hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201911_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201911_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201911_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201911_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\urls201911_hdf5.npy</td>\n",
       "      <td>201911</td>\n",
       "      <td>hdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>F:/CAPPI\\CAPPI_201912_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\CAPPI_MASK_201912_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\descriptive_data201912_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\problematic_indexes201912_hdf5.npy</td>\n",
       "      <td>F:/CAPPI\\urls201912_hdf5.npy</td>\n",
       "      <td>201912</td>\n",
       "      <td>hdf5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             CAPPI                           CAPPI_mask  \\\n",
       "0        F:/CAPPI\\CAPPI_201501.npy       F:/CAPPI\\CAPPI_MASK_201501.npy   \n",
       "1        F:/CAPPI\\CAPPI_201502.npy       F:/CAPPI\\CAPPI_MASK_201502.npy   \n",
       "2        F:/CAPPI\\CAPPI_201503.npy       F:/CAPPI\\CAPPI_MASK_201503.npy   \n",
       "3        F:/CAPPI\\CAPPI_201504.npy       F:/CAPPI\\CAPPI_MASK_201504.npy   \n",
       "4        F:/CAPPI\\CAPPI_201505.npy       F:/CAPPI\\CAPPI_MASK_201505.npy   \n",
       "..                             ...                                  ...   \n",
       "58  F:/CAPPI\\CAPPI_201908_hdf5.npy  F:/CAPPI\\CAPPI_MASK_201908_hdf5.npy   \n",
       "59  F:/CAPPI\\CAPPI_201909_hdf5.npy  F:/CAPPI\\CAPPI_MASK_201909_hdf5.npy   \n",
       "60  F:/CAPPI\\CAPPI_201910_hdf5.npy  F:/CAPPI\\CAPPI_MASK_201910_hdf5.npy   \n",
       "61  F:/CAPPI\\CAPPI_201911_hdf5.npy  F:/CAPPI\\CAPPI_MASK_201911_hdf5.npy   \n",
       "62  F:/CAPPI\\CAPPI_201912_hdf5.npy  F:/CAPPI\\CAPPI_MASK_201912_hdf5.npy   \n",
       "\n",
       "                            descriptive_data  \\\n",
       "0        F:/CAPPI\\descriptive_data201501.npy   \n",
       "1        F:/CAPPI\\descriptive_data201502.npy   \n",
       "2        F:/CAPPI\\descriptive_data201503.npy   \n",
       "3        F:/CAPPI\\descriptive_data201504.npy   \n",
       "4        F:/CAPPI\\descriptive_data201505.npy   \n",
       "..                                       ...   \n",
       "58  F:/CAPPI\\descriptive_data201908_hdf5.npy   \n",
       "59  F:/CAPPI\\descriptive_data201909_hdf5.npy   \n",
       "60  F:/CAPPI\\descriptive_data201910_hdf5.npy   \n",
       "61  F:/CAPPI\\descriptive_data201911_hdf5.npy   \n",
       "62  F:/CAPPI\\descriptive_data201912_hdf5.npy   \n",
       "\n",
       "                            problematic_indexes                          urls  \\\n",
       "0        F:/CAPPI\\problematic_indexes201501.npy       F:/CAPPI\\urls201501.npy   \n",
       "1        F:/CAPPI\\problematic_indexes201502.npy       F:/CAPPI\\urls201502.npy   \n",
       "2        F:/CAPPI\\problematic_indexes201503.npy       F:/CAPPI\\urls201503.npy   \n",
       "3        F:/CAPPI\\problematic_indexes201504.npy       F:/CAPPI\\urls201504.npy   \n",
       "4        F:/CAPPI\\problematic_indexes201505.npy       F:/CAPPI\\urls201505.npy   \n",
       "..                                          ...                           ...   \n",
       "58  F:/CAPPI\\problematic_indexes201908_hdf5.npy  F:/CAPPI\\urls201908_hdf5.npy   \n",
       "59  F:/CAPPI\\problematic_indexes201909_hdf5.npy  F:/CAPPI\\urls201909_hdf5.npy   \n",
       "60  F:/CAPPI\\problematic_indexes201910_hdf5.npy  F:/CAPPI\\urls201910_hdf5.npy   \n",
       "61  F:/CAPPI\\problematic_indexes201911_hdf5.npy  F:/CAPPI\\urls201911_hdf5.npy   \n",
       "62  F:/CAPPI\\problematic_indexes201912_hdf5.npy  F:/CAPPI\\urls201912_hdf5.npy   \n",
       "\n",
       "   yearmonth filetype  \n",
       "0     201501       h5  \n",
       "1     201502       h5  \n",
       "2     201503       h5  \n",
       "3     201504       h5  \n",
       "4     201505       h5  \n",
       "..       ...      ...  \n",
       "58    201908     hdf5  \n",
       "59    201909     hdf5  \n",
       "60    201910     hdf5  \n",
       "61    201911     hdf5  \n",
       "62    201912     hdf5  \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dates = np.load(DIR_save + 'missing_dates_all.npy', allow_pickle=True)\n",
    "dt_missing_dates = pd.to_datetime(missing_dates[:,0])\n",
    "any([i in dt_missing_dates for i in datetimes])\n",
    "    # Because of missing files that werent logged originally\n",
    "    datetimes = [i for i in datetimes if i not in dt_missing_dates]\n",
    "    print(len(datestrings),len(datetimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indxes = np.concatenate([i.ravel() for i in list(problematic_urls.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  27393.,   27394.,   27395.,   27396.,   27397.,   27398.,\n",
       "         27399.,   27400.,   27401.,   27402.,   27403.,   27404.,\n",
       "         73611.,   73612.,   73613.,   73614.,   73615.,   73616.,\n",
       "         73617.,   73618.,   73619.,   73620.,   73621.,   73622.,\n",
       "        107369.,  107370.,  107371.,  107372.,  107373.,  107374.,\n",
       "        107375.,  107376.,  107377.,  107378.,  107379.,  107380.,\n",
       "        139757.,  139758.,  139759.,  139760.,  139761.,  139762.,\n",
       "        139763.,  139764.,  139765.,  139766.,  139767.,  139768.,\n",
       "        177041.,  177042.,  177043.,  177044.,  177045.,  177046.,\n",
       "        177047.,  177048.,  177049.,  177050.,  177051.,  177052.,\n",
       "        218311.,  218312.,  218313.,  218314.,  218315.,  218316.,\n",
       "        218317.,  218318.,  218319.,  218320.,  218321.,  218322.,\n",
       "        257571.,  257572.,  257573.,  257574.,  257575.,  257576.,\n",
       "        257577.,  257578.,  257579.,  257580.,  257581.,  257582.,\n",
       "        259359.,  259360.,  259361.,  259362.,  259363.,  259364.,\n",
       "        259365.,  259366.,  259367.,  259368.,  259369.,  259370.,\n",
       "        411480.,  411481.,  411482.,  411483.,  411484.,  411485.,\n",
       "        411486.,  411487.,  411488.,  411489.,  411490.,  411491.,\n",
       "        479714.,  479715.,  479716.,  479717.,  479718.,  479719.,\n",
       "        479720.,  479721.,  479722.,  479723.,  479724.,  479725.,\n",
       "        609422.,  609423.,  609424.,  609425.,  609426.,  609427.,\n",
       "        609428.,  609429.,  609430.,  609431.,  609432.,  609433.,\n",
       "        616754.,  616755.,  616756.,  616757.,  616758.,  616759.,\n",
       "        616760.,  616761.,  616762.,  616763.,  616764.,  616765.,\n",
       "        623822.,  623823.,  623824.,  623825.,  623826.,  623827.,\n",
       "        623828.,  623829.,  623830.,  623831.,  623832.,  623833.,\n",
       "        627626.,  627627.,  627628.,  627629.,  627630.,  627631.,\n",
       "        627632.,  627633.,  627634.,  627635.,  627636.,  627637.,\n",
       "        677090.,  677091.,  677092.,  677093.,  677094.,  677095.,\n",
       "        677096.,  677097.,  677098.,  677099.,  677100.,  677101.,\n",
       "        732935.,  732936.,  732937.,  732938.,  732939.,  732940.,\n",
       "        732941.,  732942.,  732943.,  732944.,  732945.,  732946.,\n",
       "        784975.,  784976.,  784977.,  784978.,  784979.,  784980.,\n",
       "        784981.,  784982.,  784983.,  784984.,  784985.,  784986.,\n",
       "        806918.,  806919.,  806920.,  806921.,  806922.,  806923.,\n",
       "        806924.,  806925.,  806926.,  806927.,  806928.,  806929.,\n",
       "        851198.,  851199.,  851200.,  851201.,  851202.,  851203.,\n",
       "        851204.,  851205.,  851206.,  851207.,  851208.,  851209.,\n",
       "        864674.,  864675.,  864676.,  864677.,  864678.,  864679.,\n",
       "        864680.,  864681.,  864682.,  864683.,  864684.,  864685.,\n",
       "       1041222., 1041223., 1041224., 1041225., 1041226., 1041227.,\n",
       "       1041228., 1041229., 1041230., 1041231., 1041232., 1041233.,\n",
       "       1063266., 1063267., 1063268., 1063269., 1063270., 1063271.,\n",
       "       1063272., 1063273., 1063274., 1063275., 1063276., 1063277.,\n",
       "       1080213., 1080214., 1080215., 1080216., 1080217., 1080218.,\n",
       "       1080219., 1080220., 1080221., 1080222., 1080223., 1080224.,\n",
       "       1083681., 1083682., 1083683., 1083684., 1083685., 1083686.,\n",
       "       1083687., 1083688., 1083689., 1083690., 1083691., 1083692.,\n",
       "       1119523., 1119524., 1119525., 1119526., 1119527., 1119528.,\n",
       "       1119529., 1119530., 1119531., 1119532., 1119533., 1119534.,\n",
       "       1138243., 1138244., 1138245., 1138246., 1138247., 1138248.,\n",
       "       1138249., 1138250., 1138251., 1138252., 1138253., 1138254.,\n",
       "       1227380., 1227381., 1227382., 1227383., 1227384., 1227385.,\n",
       "       1227386., 1227387., 1227388., 1227389., 1227390., 1227391.,\n",
       "       1306009., 1306010., 1306012., 1306013., 1306014., 1306015.,\n",
       "       1306016., 1306017., 1306018., 1306019., 1306020., 1306021.,\n",
       "       1321332., 1321333., 1321334., 1321335., 1321336., 1321337.,\n",
       "       1321338., 1321339., 1321340., 1321341., 1321342., 1321344.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_indxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27393.0      1\n",
       "864675.0     1\n",
       "864683.0     1\n",
       "864682.0     1\n",
       "864681.0     1\n",
       "            ..\n",
       "479720.0     1\n",
       "479719.0     1\n",
       "479718.0     1\n",
       "479717.0     1\n",
       "1321344.0    1\n",
       "Length: 348, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(all_indxes).value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37b26b0919f3eebb53e1fb9d1c196dfd7351d15ccc4a50e8438da0372db545ef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('gis_wradlib_torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
